{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "import PIL.Image as img\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Dropout , Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import seaborn as sns\n",
    "import os\n",
    "from glob import glob\n",
    "import math\n",
    "from imblearn import over_sampling, under_sampling\n",
    "from IPython.display import display\n",
    "import skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your GPU(s) are:[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Your GPU(s) are:{tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp\n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp\n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp\n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp\n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"/mnt/c/Users/bveat/onedrive/documents/github/fluffy-disco\") # set path to WSL specific -- change as necessary\n",
    "data = pd.read_csv(\"./data/hmnist_28_28_L.csv\")\n",
    "metadata = pd.read_csv(\"./data/HAM10000_metadata.csv\")\n",
    "\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_types_dict = {\n",
    "    \"akiec\" : \"Actinic Keratoses\",\n",
    "    \"bcc\" : \"Basal Cell Carcinoma\",\n",
    "    \"bkl\" : \"Benign Keratosis-like Lesions\",\n",
    "    \"df\" : \"Dermatofibroma\",\n",
    "    \"mel\" : \"Melanoma\",\n",
    "    \"nv\" : \"Melanocytic Nevi\",\n",
    "    \"vasc\" : \"Vascular Lesions\"\n",
    "}\n",
    "\n",
    "# Create dict of img paths:\n",
    "base_skin_set = os.getcwd() # Note: the file must be in the \"data\" folder!\n",
    "\n",
    "image_id_path_dict = {os.path.splitext(os.path.basename(x))[0]: x\n",
    "                     for x in glob(os.path.join(base_skin_set, '*', '*.jpg'))} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>Cell_Type</th>\n",
       "      <th>Path</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>Benign Keratosis-like Lesions</td>\n",
       "      <td>/mnt/c/Users/bveat/onedrive/documents/github/f...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>Benign Keratosis-like Lesions</td>\n",
       "      <td>/mnt/c/Users/bveat/onedrive/documents/github/f...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>Benign Keratosis-like Lesions</td>\n",
       "      <td>/mnt/c/Users/bveat/onedrive/documents/github/f...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>Benign Keratosis-like Lesions</td>\n",
       "      <td>/mnt/c/Users/bveat/onedrive/documents/github/f...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>Benign Keratosis-like Lesions</td>\n",
       "      <td>/mnt/c/Users/bveat/onedrive/documents/github/f...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0027850</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>Benign Keratosis-like Lesions</td>\n",
       "      <td>/mnt/c/Users/bveat/onedrive/documents/github/f...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HAM_0002761</td>\n",
       "      <td>ISIC_0029176</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>Benign Keratosis-like Lesions</td>\n",
       "      <td>/mnt/c/Users/bveat/onedrive/documents/github/f...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HAM_0002761</td>\n",
       "      <td>ISIC_0029068</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>60.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>Benign Keratosis-like Lesions</td>\n",
       "      <td>/mnt/c/Users/bveat/onedrive/documents/github/f...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HAM_0005132</td>\n",
       "      <td>ISIC_0025837</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>Benign Keratosis-like Lesions</td>\n",
       "      <td>/mnt/c/Users/bveat/onedrive/documents/github/f...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HAM_0005132</td>\n",
       "      <td>ISIC_0025209</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>Benign Keratosis-like Lesions</td>\n",
       "      <td>/mnt/c/Users/bveat/onedrive/documents/github/f...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age     sex localization  \\\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0    male        scalp   \n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0    male        scalp   \n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0    male        scalp   \n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0    male        scalp   \n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0    male          ear   \n",
       "5  HAM_0001466  ISIC_0027850  bkl   histo  75.0    male          ear   \n",
       "6  HAM_0002761  ISIC_0029176  bkl   histo  60.0    male         face   \n",
       "7  HAM_0002761  ISIC_0029068  bkl   histo  60.0    male         face   \n",
       "8  HAM_0005132  ISIC_0025837  bkl   histo  70.0  female         back   \n",
       "9  HAM_0005132  ISIC_0025209  bkl   histo  70.0  female         back   \n",
       "\n",
       "                       Cell_Type  \\\n",
       "0  Benign Keratosis-like Lesions   \n",
       "1  Benign Keratosis-like Lesions   \n",
       "2  Benign Keratosis-like Lesions   \n",
       "3  Benign Keratosis-like Lesions   \n",
       "4  Benign Keratosis-like Lesions   \n",
       "5  Benign Keratosis-like Lesions   \n",
       "6  Benign Keratosis-like Lesions   \n",
       "7  Benign Keratosis-like Lesions   \n",
       "8  Benign Keratosis-like Lesions   \n",
       "9  Benign Keratosis-like Lesions   \n",
       "\n",
       "                                                Path  Label  \n",
       "0  /mnt/c/Users/bveat/onedrive/documents/github/f...      2  \n",
       "1  /mnt/c/Users/bveat/onedrive/documents/github/f...      2  \n",
       "2  /mnt/c/Users/bveat/onedrive/documents/github/f...      2  \n",
       "3  /mnt/c/Users/bveat/onedrive/documents/github/f...      2  \n",
       "4  /mnt/c/Users/bveat/onedrive/documents/github/f...      2  \n",
       "5  /mnt/c/Users/bveat/onedrive/documents/github/f...      2  \n",
       "6  /mnt/c/Users/bveat/onedrive/documents/github/f...      2  \n",
       "7  /mnt/c/Users/bveat/onedrive/documents/github/f...      2  \n",
       "8  /mnt/c/Users/bveat/onedrive/documents/github/f...      2  \n",
       "9  /mnt/c/Users/bveat/onedrive/documents/github/f...      2  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_data = metadata\n",
    "\n",
    "mod_data[\"Cell_Type\"] = mod_data['dx'].map(cancer_types_dict.get)\n",
    "mod_data[\"Path\"] = mod_data[\"image_id\"].map(image_id_path_dict.get)\n",
    "mod_data[\"Label\"] = pd.Categorical(mod_data['Cell_Type']).codes # Aligns data labels with .csv files in original download\n",
    "mod_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Preprocessing Function\n",
    "\n",
    "### Note to Self: Add Edge detection, Vignette detection / cropping. \n",
    "\n",
    "def preprocess(input_image):\n",
    "  image1 = input_image\n",
    "  grey = greyscale(image1)\n",
    "  contrast = apply_contrast(grey)\n",
    "  blurred = blur(contrast)\n",
    "  threshold = skimage.filters.threshold_mean(blurred)\n",
    "  mask = blurred < threshold\n",
    "  image1[~mask] = 0\n",
    "  return image1\n",
    "\n",
    "def greyscale(image):\n",
    "  image = skimage.color.rgb2gray(image)\n",
    "  #for clr in range(image.shape[2]):\n",
    "  #  image[:,:,clr]=image.mean(axis=2)\n",
    "  return image\n",
    "\n",
    "def apply_contrast(image):\n",
    "  percentiles = np.percentile(image, (0.5, 99.5))\n",
    "  # array([ 1., 28.])\n",
    "  #image_dark = skimage.exposure.adjust_gamma(image, gamma=1.5,gain=1)\n",
    "  image_bright = skimage.exposure.adjust_gamma(image, gamma=0.5,gain=1)\n",
    "  scaled = skimage.exposure.rescale_intensity(image_bright,\n",
    "                                    in_range=tuple(percentiles))\n",
    "  return scaled\n",
    "\n",
    "def blur(image):\n",
    "  blurred_image = skimage.filters.gaussian(image, sigma=1.0)\n",
    "  return blurred_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['akiec' 'bcc' 'bkl' 'df' 'mel' 'nv' 'vasc']\n",
      "['akiec' 'bcc' 'bkl' 'df' 'mel' 'nv' 'vasc']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Train_dataframe, Test_dataframe = train_test_split(mod_data, test_size = .3, stratify = mod_data[\"Label\"]) # 70-30 split\n",
    "\n",
    "display(print(np.unique(Train_dataframe[\"dx\"])), print(np.unique(Test_dataframe[\"dx\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = over_sampling.RandomOverSampler()\n",
    "Train_dataframe1, Train_dataframe1_y = oversample.fit_resample(Train_dataframe, Train_dataframe[\"Label\"])\n",
    "Test_dataframe1, Test_dataframe1_y = oversample.fit_resample(Test_dataframe, Test_dataframe[\"Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32851 validated image filenames belonging to 7 classes.\n",
      "Found 14084 validated image filenames belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "train_gen = ImageDataGenerator(rescale = 1.0 / 255, horizontal_flip = True,\n",
    "                              vertical_flip = True, brightness_range = [0.2,1.0], zoom_range = [0.5,1.0])\n",
    "\n",
    "test_gen = ImageDataGenerator(rescale = 1.0 / 255)\n",
    "\n",
    "train_data = train_gen.flow_from_dataframe(dataframe = Train_dataframe1, x_col = \"Path\", y_col = \"dx\", target_size = (128, 128), batch_size = 32,\n",
    "                                class_mode = \"categorical\", shuffle = True, seed = 1729)\n",
    "\n",
    "test_data = test_gen.flow_from_dataframe(dataframe = Test_dataframe1, x_col = \"Path\", y_col = \"dx\", target_size = (128, 128), batch_size = 32,\n",
    "                                class_mode = \"categorical\", seed = 1729)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' for batch in train_data:\\n    images = batch[0]\\n    labels = batch[1]\\n    for i in range(len(labels)):\\n        plt.imshow(images[i])\\n        plt.show()\\n        print(labels[i])\\n    break '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show images coming in small sample batch -- size 5\n",
    "\"\"\" for batch in train_data:\n",
    "    images = batch[0]\n",
    "    labels = batch[1]\n",
    "    for i in range(len(labels)):\n",
    "        plt.imshow(images[i])\n",
    "        plt.show()\n",
    "        print(labels[i])\n",
    "    break \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.utils import plot_model\n",
    "\n",
    "# Instantiate Class Inception\n",
    "\n",
    "class Inception(tf.keras.Model):\n",
    "    # Channel refers to the specific output channel for each branch; please note that channels 2 & 3 must be given as tuples.\n",
    "    def __init__(self, channel1, channel2, channel3, channel4):\n",
    "        super().__init__() \n",
    "        self.branch1_1 = tf.keras.layers.Conv2D(channel1, 1, activation = \"relu\") # Note that we add a 1x1 convolution\n",
    "        self.branch2_1 = tf.keras.layers.Conv2D(channel2[0], 1, activation = \"relu\")\n",
    "        self.branch2_2 = tf.keras.layers.Conv2D(channel2[1], 3, activation = \"relu\", padding = \"same\")\n",
    "        self.branch3_1 = tf.keras.layers.Conv2D(channel3[0], 1, activation = \"relu\")\n",
    "        self.branch3_2 = tf.keras.layers.Conv2D(channel3[1], 5, activation = \"relu\", padding = \"same\")\n",
    "        self.branch4_1 = tf.keras.layers.MaxPooling2D(pool_size = 3, strides = 1, padding = \"same\")\n",
    "        self.branch4_2 = tf.keras.layers.Conv2D(channel4, kernel_size = 1, activation = \"relu\")\n",
    "        \n",
    "    def call(self, x):\n",
    "        branch1 = self.branch1_1(x)\n",
    "        branch2 = self.branch2_2(self.branch2_1(x))\n",
    "        branch3 = self.branch3_2(self.branch3_1(x))\n",
    "        branch4 = self.branch4_2(self.branch4_1(x))\n",
    "        output = tf.keras.layers.Concatenate()([branch1, branch2, branch3, branch4])\n",
    "        return output\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-19 11:51:18.832127: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-19 11:51:18.832420: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-19 11:51:18.832471: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-19 11:51:19.590940: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-19 11:51:19.591206: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-19 11:51:19.591253: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-08-19 11:51:19.591312: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-19 11:51:19.591366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5408 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 64, 64, 64)        9472      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 32, 32, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32, 32, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 64)        4160      \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 32, 32, 192)       110784    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 16, 16, 192)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16, 16, 192)      768       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " inception (Inception)       (None, 16, 16, 256)       158316    \n",
      "                                                                 \n",
      " inception_1 (Inception)     (None, 16, 16, 480)       388736    \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 8, 8, 480)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 8, 8, 480)        1920      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " inception_2 (Inception)     (None, 8, 8, 512)         376176    \n",
      "                                                                 \n",
      " inception_3 (Inception)     (None, 8, 8, 512)         449160    \n",
      "                                                                 \n",
      " inception_4 (Inception)     (None, 8, 8, 512)         510104    \n",
      "                                                                 \n",
      " inception_5 (Inception)     (None, 8, 8, 528)         605376    \n",
      "                                                                 \n",
      " inception_6 (Inception)     (None, 8, 8, 832)         868352    \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 4, 4, 832)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 4, 4, 832)        3328      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " inception_7 (Inception)     (None, 4, 4, 832)         1043456   \n",
      "                                                                 \n",
      " inception_8 (Inception)     (None, 4, 4, 1024)        1444080   \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 2, 2, 1024)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 28679     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,784,435\n",
      "Trainable params: 22,781,299\n",
      "Non-trainable params: 3,136\n",
      "_________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "# Block One\n",
    "model.add(tf.keras.layers.Input(shape = (128, 128, 3)))\n",
    "model.add(Conv2D(64, kernel_size = 7, strides = 2, activation = \"relu\", padding = \"same\")) # 7x7, with kernel overlap\n",
    "model.add(MaxPooling2D(pool_size = 3, strides = 2, padding = \"same\"))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "# Block Two\n",
    "model.add(Conv2D(64, kernel_size = 1, activation = \"relu\"))\n",
    "model.add(Conv2D(192, kernel_size = 3, activation = \"relu\", padding = \"same\")) # 3x3 kernel; triples channels\n",
    "model.add(MaxPooling2D(pool_size = 3, strides = 2, padding = \"same\"))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "# Block Three\n",
    "model.add(Inception(64, (92, 128), (16, 32), 32))\n",
    "model.add(Inception(128, (128, 192), (32, 96), 64))\n",
    "model.add(MaxPooling2D(pool_size=3, strides=2, padding= \"same\"))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "# Block Four\n",
    "model.add(Inception(192, (96, 208), (16, 48), 64))\n",
    "model.add(Inception(160, (112, 224), (24, 64), 64))\n",
    "model.add(Inception(128, (128, 256), (24, 64), 64))\n",
    "model.add(Inception(112, (144, 288), (32, 64), 64))\n",
    "model.add(Inception(256, (160, 320), (32, 128), 128))\n",
    "model.add(MaxPooling2D(3, 2, padding = \"same\"))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "# Block Five\n",
    "model.add(Inception(256, (160, 320), (32, 128), 128))\n",
    "model.add(Inception(384, (192, 384), (48, 128), 128))\n",
    "model.add((MaxPooling2D()))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(Dense(4096, activation = \"relu\"))\n",
    "model.add(Dropout(.4))\n",
    "model.add(Dense(7, activation = \"softmax\"))\n",
    "\n",
    "# Summary & Plot\n",
    "model.summary()\n",
    "keras.utils.plot_model(model, show_shapes = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "callback = tf.keras.callbacks.ModelCheckpoint(filepath='best_model.h5',\n",
    "                                              monitor='val_acc', \n",
    "                                              mode='max',\n",
    "                                              verbose=1,\n",
    "                                              save_best_only=True)\n",
    "# Define the optimizer\n",
    "optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer = optimizer , loss = 'sparse_categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "\n",
    "# Set a learning rate annealer\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            learning_rate=0.00001)\n",
    "# Set epochs\n",
    "epochs = 25\n",
    "\n",
    "# Set batch size\n",
    "batch_size = 19 \n",
    "# As a fun fact, I chose batch size 19 because the simulated balance model has 32851 images\n",
    "# which, when divided by 19, creates 1729 batches -- the taxicab number I've been using as a \n",
    "# seed this whole time. Isn't that fun?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-19 12:24:39.802084: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-08-19 12:24:46.241766: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:417] Loaded runtime CuDNN library: 8.1.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2023-08-19 12:24:46.243136: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at conv_ops_fused_impl.h:625 : UNIMPLEMENTED: DNN library is not found.\n",
      "2023-08-19 12:24:46.243252: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:GPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): UNIMPLEMENTED: DNN library is not found.\n",
      "\t [[{{node sequential/conv2d/Relu}}]]\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node 'sequential/conv2d/Relu' defined at (most recent call last):\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_8582/2698862849.py\", line 2, in <module>\n      model.fit(\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1050, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/sequential.py\", line 412, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/keras/layers/convolutional/base_conv.py\", line 321, in call\n      return self.activation(outputs)\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/keras/activations.py\", line 317, in relu\n      return backend.relu(\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/keras/backend.py\", line 5396, in relu\n      x = tf.nn.relu(x)\nNode: 'sequential/conv2d/Relu'\nDNN library is not found.\n\t [[{{node sequential/conv2d/Relu}}]] [Op:__inference_train_function_13060]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39m/device:GPU:0\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m      3\u001b[0m         x \u001b[39m=\u001b[39;49m train_data, \n\u001b[1;32m      4\u001b[0m         validation_data \u001b[39m=\u001b[39;49m test_data, \n\u001b[1;32m      5\u001b[0m         batch_size \u001b[39m=\u001b[39;49m batch_size, \n\u001b[1;32m      6\u001b[0m         epochs \u001b[39m=\u001b[39;49m epochs\n\u001b[1;32m      7\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential/conv2d/Relu' defined at (most recent call last):\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_8582/2698862849.py\", line 2, in <module>\n      model.fit(\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1050, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/sequential.py\", line 412, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/keras/layers/convolutional/base_conv.py\", line 321, in call\n      return self.activation(outputs)\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/keras/activations.py\", line 317, in relu\n      return backend.relu(\n    File \"/home/bveatch/miniconda3/envs/tf/lib/python3.9/site-packages/keras/backend.py\", line 5396, in relu\n      x = tf.nn.relu(x)\nNode: 'sequential/conv2d/Relu'\nDNN library is not found.\n\t [[{{node sequential/conv2d/Relu}}]] [Op:__inference_train_function_13060]"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    model.fit(\n",
    "        x = train_data, \n",
    "        validation_data = test_data, \n",
    "        batch_size = batch_size, \n",
    "        epochs = epochs, \n",
    "        callbacks = [callback, learning_rate_reduction]\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
